{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9862365,"sourceType":"datasetVersion","datasetId":6053081}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\n\ntrain_data_path = '/kaggle/input/movie-ratings/movie-ratings/user_train.csv'\ndf_train = pd.read_csv(train_data_path)\n\ndf_train_features = df_train.drop(columns=['user_id', 'item_id'])\n\nX_train = df_train_features.drop(columns=['interaction']).values\nY_train = df_train_features['interaction'].values\n\n\ntest_data_path = '/kaggle/input/movie-ratings/movie-ratings/user_test.csv'\ndf_test = pd.read_csv(test_data_path)\n\ndf_test_features = df_test.drop(columns=['user_id', 'item_id'])\n\nX_test = df_test_features.drop(columns=['interaction']).values\nY_test = df_test_features['interaction'].values\n\nX_train_tensor = torch.tensor(X_train, dtype=torch.float32)\nY_train_tensor = torch.tensor(Y_train, dtype=torch.float32).view(-1, 1)\n\nX_test_tensor = torch.tensor(X_test, dtype=torch.float32)\nY_test_tensor = torch.tensor(Y_test, dtype=torch.float32).view(-1, 1)\n\nprint(f\"X_train tensor shape: {X_train_tensor.shape}\")\nprint(f\"Y_train tensor shape: {Y_train_tensor.shape}\")\nprint(f\"X_test tensor shape: {X_test_tensor.shape}\")\nprint(f\"Y_test tensor shape: {Y_test_tensor.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T06:01:21.723349Z","iopub.execute_input":"2024-11-11T06:01:21.723771Z","iopub.status.idle":"2024-11-11T06:01:22.432470Z","shell.execute_reply.started":"2024-11-11T06:01:21.723732Z","shell.execute_reply":"2024-11-11T06:01:22.431500Z"}},"outputs":[{"name":"stdout","text":"X_train tensor shape: torch.Size([90570, 40])\nY_train tensor shape: torch.Size([90570, 1])\nX_test tensor shape: torch.Size([9430, 40])\nY_test tensor shape: torch.Size([9430, 1])\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"features = len(X_train[0])\ngenres = 19\n\nprint('Total Features are', features)\nprint('Movie/Item features are: ',genres)\nprint('User-specific features are: ',features - genres)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T06:01:22.434684Z","iopub.execute_input":"2024-11-11T06:01:22.435337Z","iopub.status.idle":"2024-11-11T06:01:22.441707Z","shell.execute_reply.started":"2024-11-11T06:01:22.435291Z","shell.execute_reply":"2024-11-11T06:01:22.440689Z"}},"outputs":[{"name":"stdout","text":"Total Features are 40\nMovie/Item features are:  19\nUser-specific features are:  21\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\n\n\n\nclass MovieDataset(Dataset):\n    def __init__(self, X, Y):\n        self.x = X\n        self.y = Y\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, index):\n        return self.x[index], self.y[index]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T06:01:22.443256Z","iopub.execute_input":"2024-11-11T06:01:22.443884Z","iopub.status.idle":"2024-11-11T06:01:22.456835Z","shell.execute_reply.started":"2024-11-11T06:01:22.443835Z","shell.execute_reply":"2024-11-11T06:01:22.455980Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"train_dataset = MovieDataset(X_train, Y_train)\n\ntest_dataset = MovieDataset(X_test, Y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T06:01:22.458192Z","iopub.execute_input":"2024-11-11T06:01:22.458731Z","iopub.status.idle":"2024-11-11T06:01:22.467351Z","shell.execute_reply.started":"2024-11-11T06:01:22.458688Z","shell.execute_reply":"2024-11-11T06:01:22.466494Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n\ntest_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T06:01:22.470287Z","iopub.execute_input":"2024-11-11T06:01:22.470944Z","iopub.status.idle":"2024-11-11T06:01:22.477067Z","shell.execute_reply.started":"2024-11-11T06:01:22.470888Z","shell.execute_reply":"2024-11-11T06:01:22.476204Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"import torch\n\nimport torch.nn as nn\n\n\n\nclass DNNClassifier(nn.Module):\n\n    def __init__(self, input_dim, dropout_prob=0.2, device = 'cpu'):\n\n        super(DNNClassifier, self).__init__()\n\n        self.input_dim = input_dim\n        # Define the initial LayerNorm\n        self.layer_norm_1 = nn.LayerNorm(input_dim, device=device)\n\n        # Define layers in a single Sequential block inside ModuleList\n\n        self.layers = nn.ModuleList([\n\n            nn.Sequential(\n\n                nn.Linear(input_dim, input_dim * 2),\n                nn.ReLU(),\n                nn.Linear(input_dim * 2, input_dim * 2),\n                nn.ReLU(),\n                nn.Dropout(p=dropout_prob)\n\n            ),\n\n            nn.Sequential(\n                nn.Linear(input_dim * 2, input_dim * 2),\n                nn.ReLU(),\n                nn.Linear(input_dim * 2, input_dim),\n                nn.ReLU()\n\n            )\n\n        ])\n        # Define the final classifier layer\n        self.classifier = nn.Linear(input_dim, 1)\n        \n    def forward(self, x):\n        # Apply LayerNorm first\n        x = self.layer_norm_1(x)\n        for layer in self.layers:\n            x = layer(x)\n\n        x = self.classifier(x)\n\n        return x\n\n\n\n# Example usage\n\nmodel = DNNClassifier(input_dim=16, dropout_prob=0.2)\n\nx = torch.randn(8, 16)  # Example input: (batch_size, input_dim)\n\noutput = model(x)\n\nprint(\"Output shape:\", output.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T06:01:22.478358Z","iopub.execute_input":"2024-11-11T06:01:22.478877Z","iopub.status.idle":"2024-11-11T06:01:22.503747Z","shell.execute_reply.started":"2024-11-11T06:01:22.478838Z","shell.execute_reply":"2024-11-11T06:01:22.502863Z"}},"outputs":[{"name":"stdout","text":"Output shape: torch.Size([8, 1])\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"params = 0\n\nfor parameters in model.parameters():\n    params += sum([p.numel() for p in parameters])\n\nprint('Total parameters are: ', params)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T06:01:22.504769Z","iopub.execute_input":"2024-11-11T06:01:22.505497Z","iopub.status.idle":"2024-11-11T06:01:22.511843Z","shell.execute_reply.started":"2024-11-11T06:01:22.505464Z","shell.execute_reply":"2024-11-11T06:01:22.510823Z"}},"outputs":[{"name":"stdout","text":"Total parameters are:  3233\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"import torch\nimport torch.optim as optim\nimport torch.nn as nn\nfrom tqdm import tqdm  # Importing tqdm\n\n# Hyperparameters\ninput_dim = features  # Define 'features' as the number of input features (e.g., number of columns in your data)\nlearning_rate = 0.001\nnum_epochs = 20\ndropout_prob = 0.2\n\n# Device configuration (use GPU if available)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Initialize the model, loss function, and optimizer\nmodel = DNNClassifier(input_dim=input_dim, dropout_prob=dropout_prob).to(device)\ncriterion = nn.BCEWithLogitsLoss()  # Combines sigmoid with binary cross-entropy loss\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\nloss_list = []\n\n# Training loop with tqdm progress bar\nfor epoch in range(num_epochs):\n    # Wrapping the training loop with tqdm to display a progress bar\n    with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\", unit='batch') as pbar:\n        train_loss = 0.0\n        model.train()\n        \n        # Iterate over the batches in the train_loader\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device).to(torch.float32), labels.to(device).to(torch.float32)\n            \n            # Forward pass\n            outputs = model(inputs).to(torch.float32)\n            loss = criterion(outputs, labels.view(-1, 1))\n            \n            # Backward pass and optimization\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            # Track loss\n            train_loss += loss.item() * inputs.size(0)\n            \n            # Update the progress bar\n            pbar.set_postfix(loss=train_loss / (pbar.n + 1))\n            pbar.update(1)  # Increment the progress bar by one batch\n    \n    avg_train_loss = train_loss / len(train_loader.dataset)\n    print(f\"\\nEpoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_train_loss:.4f}\")\n    print('-' * 50)\n    loss_list.append(avg_train_loss)\n\n# Saving the trained model\ntorch.save(model.state_dict(), 'dnn_classifier.pth')\nprint(\"Model saved successfully.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T06:01:22.513167Z","iopub.execute_input":"2024-11-11T06:01:22.513700Z","iopub.status.idle":"2024-11-11T06:05:09.284804Z","shell.execute_reply.started":"2024-11-11T06:01:22.513658Z","shell.execute_reply":"2024-11-11T06:05:09.283871Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/20: 100%|██████████| 2831/2831 [00:11<00:00, 250.55batch/s, loss=15]  \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch [1/20] - Train Loss: 0.4674\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/20: 100%|██████████| 2831/2831 [00:11<00:00, 250.75batch/s, loss=14.8]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch [2/20] - Train Loss: 0.4616\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/20: 100%|██████████| 2831/2831 [00:11<00:00, 244.65batch/s, loss=14.7]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch [3/20] - Train Loss: 0.4597\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/20: 100%|██████████| 2831/2831 [00:11<00:00, 252.60batch/s, loss=14.6]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch [4/20] - Train Loss: 0.4577\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/20: 100%|██████████| 2831/2831 [00:11<00:00, 249.42batch/s, loss=14.6]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch [5/20] - Train Loss: 0.4559\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/20: 100%|██████████| 2831/2831 [00:11<00:00, 248.34batch/s, loss=14.6]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch [6/20] - Train Loss: 0.4548\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/20: 100%|██████████| 2831/2831 [00:11<00:00, 249.66batch/s, loss=14.5]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch [7/20] - Train Loss: 0.4534\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/20: 100%|██████████| 2831/2831 [00:11<00:00, 250.69batch/s, loss=14.5]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch [8/20] - Train Loss: 0.4529\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/20: 100%|██████████| 2831/2831 [00:11<00:00, 247.11batch/s, loss=14.5]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch [9/20] - Train Loss: 0.4521\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/20: 100%|██████████| 2831/2831 [00:11<00:00, 251.92batch/s, loss=14.4]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch [10/20] - Train Loss: 0.4509\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/20: 100%|██████████| 2831/2831 [00:11<00:00, 251.92batch/s, loss=14.4]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch [11/20] - Train Loss: 0.4495\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/20: 100%|██████████| 2831/2831 [00:11<00:00, 248.50batch/s, loss=14.4]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch [12/20] - Train Loss: 0.4490\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/20: 100%|██████████| 2831/2831 [00:11<00:00, 251.57batch/s, loss=14.3]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch [13/20] - Train Loss: 0.4478\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/20: 100%|██████████| 2831/2831 [00:11<00:00, 251.01batch/s, loss=14.3]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch [14/20] - Train Loss: 0.4472\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/20: 100%|██████████| 2831/2831 [00:11<00:00, 247.02batch/s, loss=14.2]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch [15/20] - Train Loss: 0.4454\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/20: 100%|██████████| 2831/2831 [00:11<00:00, 252.50batch/s, loss=14.2]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch [16/20] - Train Loss: 0.4446\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/20: 100%|██████████| 2831/2831 [00:11<00:00, 247.33batch/s, loss=14.2]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch [17/20] - Train Loss: 0.4433\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/20: 100%|██████████| 2831/2831 [00:11<00:00, 251.29batch/s, loss=14.2]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch [18/20] - Train Loss: 0.4423\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/20: 100%|██████████| 2831/2831 [00:11<00:00, 251.62batch/s, loss=14.1]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch [19/20] - Train Loss: 0.4410\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/20: 100%|██████████| 2831/2831 [00:11<00:00, 247.53batch/s, loss=14.1]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch [20/20] - Train Loss: 0.4396\n--------------------------------------------------\nModel saved successfully.\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"def evaluate(model, test_loader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n\n        for inputs, labels in test_loader:\n\n            inputs, labels = inputs.to(device).to(torch.float32), labels.to(device).to(torch.float32)            \n            # Forward pass\n\n            outputs = model(inputs).to(torch.float32)\n            loss = criterion(outputs, labels.view(-1, 1))\n\n            # Track loss and accuracy\n            running_loss += loss.item() * inputs.size(0)\n            outputs = torch.sigmoid(outputs)\n            predicted = (outputs > 0.5).float()\n            correct += (predicted == labels.view(-1, 1)).sum().item()\n            total += labels.size(0)\n\n    \n\n    avg_loss = running_loss / total\n    accuracy = correct / total\n    return avg_loss, accuracy\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T06:05:09.286171Z","iopub.execute_input":"2024-11-11T06:05:09.286889Z","iopub.status.idle":"2024-11-11T06:05:09.295567Z","shell.execute_reply.started":"2024-11-11T06:05:09.286842Z","shell.execute_reply":"2024-11-11T06:05:09.294721Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T06:05:09.296558Z","iopub.execute_input":"2024-11-11T06:05:09.296921Z","iopub.status.idle":"2024-11-11T06:05:09.634162Z","shell.execute_reply.started":"2024-11-11T06:05:09.296881Z","shell.execute_reply":"2024-11-11T06:05:09.633145Z"}},"outputs":[{"name":"stdout","text":"Test Loss: 0.4286, Test Accuracy: 0.8370\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}